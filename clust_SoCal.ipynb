{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582ef5f5",
   "metadata": {},
   "source": [
    "# Sample script of clustering analysis applied to a relocated seismicity catalog from Southern California see:\n",
    "Hauksson, Egill, Wenzheng Yang, and Peter M. Shearer. \"Waveform relocated earthquake catalog for southern California (1981 to June 2011).\" Bulletin of the Seismological Society of America 102.5 (2012): 2239-2244.\n",
    "\n",
    "    and\n",
    "    \n",
    "Zaliapin, Ilya, and Yehuda Ben‐Zion. \"Earthquake clusters in southern California I: Identification and stability.\" Journal of Geophysical Research: Solid Earth 118.6 (2013): 2847-2864.\n",
    "\n",
    "    and\n",
    "    \n",
    "    Goebel, T.H.W., Rosson, Z., Brodsky, E.E., and Walter, J.I., 2019, Aftershock deficiency of induced earthquake sequences during rapid mitigation efforts in Oklahoma: Earth and Planetary Science Letters, v. 522, p. 135–143, doi: 10.1016/j.epsl.2019.06.036.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa8acfa",
   "metadata": {},
   "source": [
    "### the following code performs three primary steps:\n",
    "    1. calculated nearest-neighbor distance between all events in the catalog\n",
    "    2. separate the seismicity catalog into families and indpendent background events based on nearest-neighbor threshold\n",
    "    3. Count the number of aftershocks for each family and plot number of aftershocks over mainshock magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe1ad2d",
   "metadata": {},
   "source": [
    "### 0: seismicity map\n",
    "Load Southern California seismicity catalog and plot with Basemap. \n",
    "(this step can be skipped if the mpl Basemap module is not installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd213067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify data file, time and magnitude range\n",
    "dir_in = 'data'\n",
    "# this file is generated with: 1_create_mat_eqCat_file.py\n",
    "file_in= 'hs_1981_2011_all.mat'\n",
    "# completeness magntiude = Mmin, and Mmax (which does not need to be specified)\n",
    "Mmin, Mmax = 3, None\n",
    "tmin, tmax = 1980, 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a214aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#------------------------------my modules-------------------------------------- \n",
    "# EqCat is a Python object that is used for catlog processing\n",
    "from src.EqCat import EqCat\n",
    "eqCat = EqCat( )\n",
    "#for methods check source code or uncomment the following line \n",
    "print( 'EqCat Methods: ', eqCat.methods)\n",
    "#=================================2==============================================\n",
    "#                            load data, select events\n",
    "#================================================================================\n",
    "eqCat.loadMatBin( f\"{dir_in}/{file_in}\")\n",
    "print(  'total no. of events', eqCat.size())\n",
    "eqCat.selectEvents( Mmin, Mmax, 'Mag')\n",
    "eqCat.selectEvents( tmin, tmax, 'Time')\n",
    "print( 'no. of events after Mag/Time selection', eqCat.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c09a3",
   "metadata": {},
   "source": [
    "the following cell will only run if you have Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a3caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #os.environ[\"PROJ_LIB\"] = f\"{os.environ['HOME']}/opt/anaconda3/share/proj\"\n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "    b_map = True\n",
    "except:\n",
    "    b_map = False\n",
    "#=================================3==============================================\n",
    "#                          test plot with Basemap\n",
    "#================================================================================\n",
    "projection = 'cyl'\n",
    "xmin,xmax = eqCat.data['Lon'].min(), eqCat.data['Lon'].max()\n",
    "ymin,ymax = eqCat.data['Lat'].min(), eqCat.data['Lat'].max()\n",
    "if b_map:\n",
    "    # setup equi distance basemap.\n",
    "    m = Basemap( llcrnrlat  =  ymin,urcrnrlat  =  ymax,\n",
    "                 llcrnrlon  =  xmin,urcrnrlon  =  xmax,\n",
    "                 projection = projection,lat_0=(ymin+ymax)*.5,lon_0=(xmin+xmax)*.5,\n",
    "                 resolution = 'l')\n",
    "    m.drawstates( linewidth = 1)\n",
    "    m.drawcoastlines( linewidth= 2)\n",
    "    a_x, a_y = m( eqCat.data['Lon'], eqCat.data['Lat'])\n",
    "    m.plot( a_x, a_y, 'ko', ms = 1)\n",
    "    sel6 = eqCat.data['Mag'] >= 6\n",
    "    m.plot( a_x[sel6], a_y[sel6], 'ro', ms = 8, mew= 1.5, mfc = 'none')\n",
    "\n",
    "    m.drawmeridians( np.linspace( int(xmin), xmax, 4),labels=[False,False,False,True],\n",
    "                     fontsize = 12, fmt = '%.1f')\n",
    "    m.drawparallels( np.linspace( int(ymin), ymax, 4),labels=[True,False,False,False],\n",
    "                     fontsize = 12, fmt = '%.2f')\n",
    "\n",
    "    plt.savefig( file_in.replace( 'mat', 'png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e4096",
   "metadata": {},
   "source": [
    "### 1: Compute Nearest Neighbor Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069c432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.clustering as clustering\n",
    "# set parameters:fractal dimension and b-value\n",
    "dPar  = {   # fractal dimension and b for eq. (1) in Zaliapin & Ben-Zion\n",
    "            'D'           : 1.6, # TODO: - these values should be contrained independently\n",
    "            'b'           : 1.0, # use: https://github.com/tgoebel/magnitude-distribution for b-value\n",
    "            'Mc'          : Mmin,\n",
    "            #=================plotting==============\n",
    "             # these parameters rarely have to be changes\n",
    "            'eta_binsize' :  .3,\n",
    "            'xmin' : -13, 'xmax' : 0,\n",
    "          }\n",
    "\n",
    "\n",
    "#================================================================================\n",
    "#                           to cartesian coordinates\n",
    "#================================================================================\n",
    "# two ways to do the distance comp: 1 project into equal distance azimuthal , comp Cartersian distance in 3D\n",
    "#                                   2 get surface distance from lon, lat (haversine), use pythagoras to include depth\n",
    "if b_map:\n",
    "    eqCat.toCart_coordinates( projection = 'eqdc')\n",
    "    print( 'convert to cartesian using equi-distant projection')\n",
    "#==================================2=============================================\n",
    "#                       compute space-time-magnitude distance, histogram\n",
    "#================================================================================\n",
    "eqCat.data['Z'] = eqCat.data['Depth']\n",
    "print('depth range: ', eqCat.data['Z'].min(), eqCat.data['Z'].max())\n",
    "dNND = clustering.NND_eta( eqCat, dPar,  \n",
    "                              correct_co_located = True, verbose= True)\n",
    "###histogram\n",
    "aBins        = np.arange( -13, 1, dPar['eta_binsize'], dtype = float)\n",
    "aHist, aBins = np.histogram( np.log10( dNND['aNND'][dNND['aNND']>0]), aBins)\n",
    "aBins = aBins[0:-1] + dPar['eta_binsize']*.5\n",
    "# correct for binsize\n",
    "aHist = aHist/dPar['eta_binsize']\n",
    "# to pdf (prob. density)\n",
    "aHist /= eqCat.size()\n",
    "#=================================3==============================================\n",
    "#                            save results\n",
    "#================================================================================\n",
    "import scipy.io\n",
    "NND_file = 'data/%s_NND_Mc_%.1f.mat'%( file_in.split('.')[0], dPar['Mc'])\n",
    "print( 'save file', NND_file)\n",
    "scipy.io.savemat( NND_file, dNND, do_compression  = True)\n",
    "\n",
    "#=================================4==============================================\n",
    "#                          plot histogram\n",
    "#================================================================================\n",
    "# load eta_0 value - only for plotting purposes\n",
    "eta_0_file = '%s/%s_Mc_%.1f_eta_0.txt'%(dir_in, file_in, dPar['Mc'])\n",
    "if os.path.isfile( eta_0_file):\n",
    "    print( 'load eta_0 from file'),\n",
    "    f_eta_0 = np.loadtxt( eta_0_file, dtype = float)\n",
    "    print( 'eta_0',f_eta_0)\n",
    "else:\n",
    "    f_eta_0 = -5\n",
    "    print( 'could not find eta_0 file', eta_0_file, 'use value: ', f_eta_0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#ax.plot( vBin, vHist, 'ko')\n",
    "ax.bar( aBins, aHist, width =.8*dPar['eta_binsize'], align = 'edge', color = '.5', label = 'Mc = %.1f'%( dPar['Mc']))\n",
    "ax.plot( [f_eta_0, f_eta_0], ax.get_ylim(), 'w-',  lw = 2, label = '$N_\\mathrm{tot}$=%i'%( eqCat.size()))\n",
    "ax.plot( [f_eta_0, f_eta_0], ax.get_ylim(), 'r--', lw = 2, label = '$N_\\mathrm{cl}$=%i'%( dNND['aNND'][dNND['aNND']<1e-5].shape[0]))\n",
    "\n",
    "ax.legend( loc = 'upper left')\n",
    "ax.set_xlabel( 'NND, log$_{10} \\eta$')\n",
    "ax.set_ylabel( 'Number of Events')\n",
    "ax.grid( 'on')\n",
    "ax.set_xlim( dPar['xmin'], dPar['xmax'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b4dce8",
   "metadata": {},
   "source": [
    "The above figure shows a histogram of nearest parent space-time-magnitude distance in the catalog. \n",
    "Note that two distinct modes arise from a typical earthquake catalog: a clustered mode (left) \n",
    "and a background mode (right). The former represent omori-type clustering (typically 'nearer') while the latter represents the background poisson process. Earthquakes in the background mode are earthquakes that, observably, are not triggered from a previous earthquake. $\\eta_0$ is the cutoff between these two modes. Practically, this will result in all connections between earethquakes exceeding this cutoff will be removed, thus forming distinct clusters of earthquakes.\n",
    "\n",
    "For a quick analysis, it is possible to simply pick a value that separates these modes. Smaller values will lead to smaller clusters, larger values will lead to more generous clusters but may include background seismicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf12b34a",
   "metadata": {},
   "source": [
    "### 2: separate clusters from independent background and compile event families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b874317",
   "metadata": {},
   "outputs": [],
   "source": [
    "dPar['eta_0'] = f_eta_0\n",
    "print( 'similarity threshold', dPar['eta_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47685619",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_file = file_in.replace( 'all.mat', 'Mc_%.1f_clusters.mat'%( dPar['Mc']))\n",
    "    \n",
    "dNND['aNND'] = np.log10( dNND['aNND'])\n",
    "# clustering according to eta_0 similarity criteria\n",
    "dClust = clustering.compileClust( dNND, f_eta_0, useLargerEvents = False)\n",
    "#=================================4==========================================================================\n",
    "#                           save results\n",
    "#============================================================================================================\n",
    "scipy.io.savemat( os.path.join( dir_in,clust_file), dClust, do_compression=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab2cd5",
   "metadata": {},
   "source": [
    "### let's create a couple of test plots to check whether everythin is working\n",
    "the first plot provides a rough overview of clustered and independent events in a rescale space-time domain\n",
    "\n",
    "This provides a visualization of the clustering behavior outlined above. This time in normalized space distance ($R_{ij}$) versus normalized time distance ($T_{ij}$). Where:\n",
    "\n",
    "$$ R_{ij} = r_{ij}^d\\times10^{bM_i/2} $$\n",
    "$$ T_{ij} = t_{ij}\\times10^{bM_i/2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======event-pair density in r-T============================\n",
    "catChild=  EqCat()\n",
    "catParent= EqCat()\n",
    "catChild.copy(  eqCat)\n",
    "catParent.copy( eqCat)\n",
    "catChild.selEventsFromID(    dNND['aEqID_c'], repeats = True)\n",
    "catParent.selEventsFromID(   dNND['aEqID_p'], repeats = True)\n",
    "print( 'size of offspring catalog', catChild.size(), 'size of parent cat', catParent.size())  \n",
    "\n",
    "#compute re-scaled interevent times and distances\n",
    "a_R, a_T = clustering.rescaled_t_r(catChild, catParent, dPar)\n",
    "# plot event pair density \n",
    "fig = clustering.plot_R_T( a_T, a_R, f_eta_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53670ed",
   "metadata": {},
   "source": [
    "as you can see there are two different statistical modes \n",
    "(sort of like peaks in a histogram except for now you are looking at a 2D histogram)\n",
    "Which mode (red area) correponds to the background events and which mode marks the aftershocks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b47fc42",
   "metadata": {},
   "source": [
    "Now let's also look at the different families and how individual events are linked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================4=============================================\n",
    "#                          spanning tree\n",
    "#================================================================================\n",
    "plt.figure( 1)\n",
    "ax = plt.subplot(111)  \n",
    "for iEv in range( catParent.size()):\n",
    "    print( f\"MS-ID, {int(catParent.data['N'][iEv]):d}, t-Par: {catParent.data['Time'][iEv]:.5f},'t-child', {eqCat.data['Time'][iEv]:.5f}\", end= \"\\r\")\n",
    "\n",
    "    if dNND['aNND'][iEv] < dPar['eta_0']:#triggered cluster\n",
    "        ax.plot( [catParent.data['Time'][iEv]], [catParent.data['Lat'][iEv]], 'ro', ms = 12, alpha = .2)\n",
    "        ax.plot( [catParent.data['Time'][iEv],catChild.data['Time'][iEv]],\n",
    "                  [catParent.data['Lat'][iEv], catChild.data['Lat'][iEv]], 'k-', marker = 'o', ms = 4, mew =1, mfc = 'none')\n",
    "    else: # independent events\n",
    "        ax.plot( [catChild.data['Time'][iEv]], [catChild.data['Lat'][iEv]], 'bo', ms = 5, alpha = .6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcae05b9",
   "metadata": {},
   "source": [
    "The blue dots in the above plot are independent background events. That means their nearest neighbor\n",
    "is beyond the chosen (or calculated) eta_0 value.\n",
    "The red and black circles are clustered events linked by thin black lines.\n",
    "The darker the red color the more events are linked to that particular parent.\n",
    "Black circles are the last generation in a trigger series, i.e., aftershocks that do not produce aftershocks\n",
    "themselves.\n",
    "Can you dedetect some major triggering events? (Hint: think about major eqs. in 1992, 1999, 2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58990e83",
   "metadata": {},
   "source": [
    "### 3: count aftershocks and plot productivity relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdbfb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqCat = EqCat( )\n",
    "#=================================1==============================================\n",
    "#                            load data, select events\n",
    "#================================================================================\n",
    "eqCat.loadMatBin( f\"{dir_in}/{file_in}\")\n",
    "eqCat.selectEvents( Mmin, Mmax, 'Mag')\n",
    "eqCat.selectEvents( tmin, tmax, 'Time')\n",
    "N_tot = eqCat.size()\n",
    "print(  'total no. of events', N_tot)\n",
    "#=================================2==========================================================================\n",
    "#                     singles are counted as MS with 0 AS\n",
    "#============================================================================================================\n",
    "print( 'total number of clusters', len(  dClust.keys()), 'no. of BG events', dClust['0'].shape[0])\n",
    "a_ID_single  = dClust['0']\n",
    "\n",
    "# IDs of BG events\n",
    "a_iSel       = np.zeros( eqCat.size(), dtype = int)\n",
    "a_mag_single = np.zeros( len( a_ID_single))\n",
    "a_N_AS_single= np.zeros( len( a_ID_single))\n",
    "a_N_FS_single= np.zeros( len( a_ID_single))\n",
    "for i in range( a_ID_single.shape[0]):\n",
    "    # event ID may be in catalog more than once\n",
    "    sel_ev          = eqCat.data['N'] == a_ID_single[i]\n",
    "    a_mag_single[i] = eqCat.data['Mag'][sel_ev][0]\n",
    "    a_iSel[sel_ev] = 1#catalog.data['N'][catalog.data['N']==aEqID[i]][0]\n",
    "    if sel_ev.sum() != 1:\n",
    "        error_str = 'more than event found', eqCat.data['N'][sel_ev]\n",
    "        raise( ValueError( error_str))\n",
    "### remove singles from catalog\n",
    "eqCat.selDicAll( np.logical_not(a_iSel))\n",
    "print( 'remaining events', eqCat.size(), 'BG events', len( a_mag_single))\n",
    "dClust.pop('0') # remove singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#=================================2==========================================================================\n",
    "#                   get MAGs of MS with aftershocks, count aftershocks\n",
    "#============================================================================================================\n",
    "a_N_FS    = np.zeros( len( dClust.keys()), dtype = int)\n",
    "a_N_AS    = np.zeros( len( dClust.keys()), dtype = int)\n",
    "a_MS_mag  = np.zeros( len( dClust.keys()))\n",
    "a_MS_ID   = np.zeros( len( dClust.keys()), dtype = int)\n",
    "iCl = 0\n",
    "for sCl in dClust.keys():\n",
    "    aEqID = dClust[sCl]# np.unique( dClust[sCl].flatten()) unique is not needed anymore, createCluster has been fixed\n",
    "    print( 'cl: ', iCl+1,'out of: ', len( dClust.keys()), 'no. of ev. in cl.', \n",
    "          len( aEqID), len( np.unique( dClust[sCl])), end=\"\\r\")\n",
    "    # find MS mag and magnitude of entire family\n",
    "    atmp_MAG = np.zeros( len( aEqID))\n",
    "    atmp_Time= np.zeros( len( aEqID))\n",
    "    a_iSel   = np.zeros( eqCat.size(), dtype = int)\n",
    "    # for each family find: event mag. and origin time\n",
    "    for iM in range( len( aEqID)):\n",
    "        sel_ev        = eqCat.data['N'] == aEqID[iM]\n",
    "        if sel_ev.sum() != 1:\n",
    "            error_str = 'more/less than event found', eqCat.data['N'][sel_ev], aEqID[iM]\n",
    "            raise(  ValueError, error_str)\n",
    "        atmp_MAG[iM]  = eqCat.data['Mag'][sel_ev][0]\n",
    "        atmp_Time[iM] = eqCat.data['Time'][sel_ev][0]\n",
    "        a_iSel[sel_ev] = 1\n",
    "    # remove events from catalog\n",
    "    #catalog.selDicAll( np.logical_not(a_iSel))\n",
    "    #----------------------------mainshock-------------------------------------------------- \n",
    "    selMS     = atmp_MAG == atmp_MAG.max()\n",
    "    f_tMS     = atmp_Time[selMS][0]\n",
    "    i_ID_MS   = aEqID[selMS]\n",
    "\n",
    "    #print( 'tMS', tMS, v_currEqID.shape[0], 'MAG', curr_cat.data['MAG'][selMS][0]\n",
    "    #----------------------------aftershock-------------------------------------------------- \n",
    "    selAS     = atmp_Time > f_tMS\n",
    "    selFS     = atmp_Time < f_tMS\n",
    "    #print( 'no. of aftershocks', selAS.sum()\n",
    "    # save number of aftershocks for each MS mag\n",
    "    a_MS_mag[iCl] = atmp_MAG[selMS][0]#, dPar['magRound'])\n",
    "    a_N_AS[iCl]   = selAS.sum()\n",
    "    a_N_FS[iCl]   = selFS.sum()\n",
    "    a_MS_ID[iCl]  = int( i_ID_MS[0])\n",
    "    iCl += 1\n",
    "\n",
    "#=================================3==========================================================================\n",
    "#                  compare MS+single+FS+AS to original number of events in catalog\n",
    "#============================================================================================================\n",
    "# combine single without AS with mainshocks that do have aftershocks\n",
    "a_N_FS    = np.append( a_N_FS, a_N_FS_single)\n",
    "a_N_AS    = np.append( a_N_AS, a_N_AS_single)\n",
    "a_MS_mag  = np.append( a_MS_mag, a_mag_single)\n",
    "a_MS_ID   = np.append( a_MS_ID, a_ID_single)\n",
    "print( 'tot ev. in catalog', N_tot,'tot events in families',a_N_FS.sum() + a_N_AS.sum() + a_MS_mag.shape[0])\n",
    "#print( 'N BG', a_mag_single.shape[0], 'FS', a_N_FS_single.sum(), 'AS', a_N_AS_single.sum(), 'MS (MS+BG)', a_MS_mag.shape[0]\n",
    "\n",
    "#=================================4==========================================================================\n",
    "#                    save to ASCII text\n",
    "#============================================================================================================\n",
    "file_out = '%s/%s_Nas_MS_Mc_%.1f.txt'%(dir_in, file_in.split('.')[0], dPar['Mc'])#, dPar['magRound'])\n",
    "m_N_as   = np.array([a_MS_mag, a_N_AS, a_N_FS, a_MS_ID])\n",
    "np.savetxt( file_out, m_N_as.T, fmt='%10.3f%10i%10i%14i',\n",
    "            header = 'MAG          N-AS          N-FS        MS-ID; note N_AS=0 highlights singles or FS only')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2290ea",
   "metadata": {},
   "source": [
    "the two numbers above should hopefully match, otherwise you may have to rerun the code from the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a66f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "dPar['magRound'] = 1 # binning\n",
    "#=================plotting==============\n",
    "dPar['alpha']    =  1.0 # power law exponent\n",
    "dPar['xmin']     =  2  \n",
    "dPar['xmax']     =  8\n",
    "dPar['ymin']     = 0.1  \n",
    "dPar['ymax']     = 1e4\n",
    "\n",
    "#=================================2==========================================================================\n",
    "#                           count ave. no. of aftershocks per MS magnitude\n",
    "#============================================================================================================\n",
    "aMag_round= np.around( m_N_as[0], dPar['magRound'])\n",
    "aMag_bin  = np.array( sorted(np.unique( aMag_round)))\n",
    "aAveNo_AS = np.ones( len( aMag_bin))*np.nan\n",
    "aNo_Fam   = np.zeros( len( aMag_bin)) # total number of families within mag bin\n",
    "aNo_AS20  = np.zeros( len( aMag_bin))\n",
    "aNo_AS80  = np.zeros( len( aMag_bin))\n",
    "\n",
    "i = 0\n",
    "for curr_mag in aMag_bin:\n",
    "    selMag       = curr_mag == aMag_round\n",
    "    aAveNo_AS[i] = m_N_as[1][selMag].mean()\n",
    "    if selMag.sum() > 0:\n",
    "        aNo_AS20[i]  = np.percentile( m_N_as[1][selMag], 20)\n",
    "        aNo_AS80[i]  = np.percentile( m_N_as[1][selMag], 80)\n",
    "    aNo_Fam[i]   = selMag.sum()\n",
    "    print( curr_mag, 'mean N-AS', round(aAveNo_AS[i],2),  aNo_AS20[i],aNo_AS80[i], 'no. of fam', aNo_Fam[i],end=\"\\r\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "#=================================3==========================================================================\n",
    "#                           plot productivity law\n",
    "#============================================================================================================\n",
    "plt.figure(1, figsize=(8,6))\n",
    "ax = plt.axes([.14,.12,.78,.83])#pPlot.createFigureSquare(1)\n",
    "ax.semilogy( m_N_as[0],   m_N_as[1],     'o',  ms = 6, mew =0, mfc = '.7', alpha = .2 )\n",
    "#ax.errorbar( aMag_bin,  aAveNo_AS, yerr=[np.zeros(aMag_bin.shape[0]), aNo_AS80-aAveNo_AS],\n",
    "#             fmt = 'o', ecolor = 'k', elinewidth=.7,capsize=2.5, mec = 'k', ms = 8, mew = 1, mfc = 'w')\n",
    "ax.errorbar( aMag_bin,  aAveNo_AS, yerr=[aAveNo_AS-aNo_AS20, aNo_AS80-aAveNo_AS],\n",
    "             fmt = 'o', ecolor = 'k', elinewidth=.7,capsize=2.5, mec = 'k', ms = 8, mew = 1, mfc = 'w')\n",
    "\n",
    "#-------------------------exponential - estimate-----------------------------------------------------\n",
    "mag_fit    = aMag_bin[10] # force fit through this point\n",
    "f_no_AS_pl = aAveNo_AS[aMag_bin == mag_fit]\n",
    "preFac     = np.log10( f_no_AS_pl) - dPar['alpha']*mag_fit\n",
    "a_N_hat    = 10**( dPar['alpha']*aMag_bin + preFac)\n",
    "ax.semilogy( aMag_bin, a_N_hat, 'w-')\n",
    "ax.semilogy( aMag_bin, a_N_hat, '-', color = 'r', lw = 2, label = 'exp = %.1f'%( np.round( dPar['alpha'],1)))\n",
    "\n",
    "#-------------------------------labels, limits etc.-----------------------------------------------\n",
    "ax.set_xlim( dPar['xmin'], dPar['xmax'])\n",
    "ax.set_ylim( dPar['ymin'], dPar['ymax'])\n",
    "ax.set_xlabel( 'Mainshock Magnitude')\n",
    "ax.set_ylabel( 'Number of Aftershocks')\n",
    "ax.legend( loc = 'upper left', frameon = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9a928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
